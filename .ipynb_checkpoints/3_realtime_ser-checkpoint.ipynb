{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MeidanGR/SpeechEmotionRecognition_Realtime/blob/main/3_realtime_ser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2QAnJ2-D_G0"
   },
   "source": [
    "# **Speech Emotion Recognition (Classification) in real-time using Deep LSTM layers**\n",
    "### ***Real-time implementaion of the SER model***\n",
    "---\n",
    "\n",
    "### Final project (B.Sc. requirement)  \n",
    "Development by **Meidan Greenberg & Linoy Hadad.**\n",
    "\n",
    "Instructor: **Dr. Dima Alberg**\n",
    "\n",
    "Industial Engineering and Management dept.\n",
    "\n",
    "SCE Collage, Israel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Gcq7z02GfSH"
   },
   "source": [
    "# **ABSTRACT**\n",
    "This implementation of the pre-developed speech emotion recognition (SER) model is intended to analyze a speech audio input in real-time, identify and present the expressed emotion within it.\n",
    "\n",
    "\n",
    "Classifying emotion from speech is a long-term problem rather than a short-term one. In Linguistics, two same phrases of speech can receive a different meaning just by emphasizing a word or even a syllable.\n",
    "\n",
    "The model, an 87.23% accuracy LSTM based deep learning network, had learned how to classify the correct emotion expressed in a long-time sequence of speech features extracted from the audio signal.\n",
    "\n",
    "This system will record audio input, create a temporary .wav file containing the audio signals recorded, preprocess it, and present the distribution of emotions found in speech. The sequence length chosen for the task is 7.1 seconds.\n",
    "The process is cyclic and continues to accrue as long as there is continuous speech. After a silence of 2 seconds or more at the end of a sentence, the process will cease. At the end of a session, a summary is presented, holding the mean values of all emotions recognized during the session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGNQaFNUEQMm"
   },
   "source": [
    "# **LIBRARIES & GOOGLE AUTH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RVEzIMYrFpEf",
    "outputId": "7366d8fb-848a-4f7e-c976-3624260b14ab"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'termios'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-148b7e1789d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cpc\\lib\\site-packages\\google\\colab\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_installation_commands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_shell_customizations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_tensorflow_magics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cpc\\lib\\site-packages\\google\\colab\\_system_commands.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlocale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cpc\\lib\\pty.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselect\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mselect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"openpty\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"fork\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"spawn\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\cpc\\lib\\tty.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Author: Steen Lumholt.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtermios\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"setraw\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"setcbreak\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'termios'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "lA4vLC6ID715"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pydub\n",
    "!pip install noisereduce\n",
    "#!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n",
    "!pip install pyaudio\n",
    "!pip install json-tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.11.tar.gz (37 kB)\n",
      "Building wheels for collected packages: pyaudio\n",
      "  Building wheel for pyaudio (setup.py): started\n",
      "  Building wheel for pyaudio (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pyaudio\n",
      "Failed to build pyaudio\n",
      "Installing collected packages: pyaudio\n",
      "    Running setup.py install for pyaudio: started\n",
      "    Running setup.py install for pyaudio: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\Users\\luca_\\.conda\\envs\\tf\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\luca_\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oxtzhzjj\\\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\luca_\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oxtzhzjj\\\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\luca_\\AppData\\Local\\Temp\\pip-wheel-d0mg0wtk'\n",
      "       cwd: C:\\Users\\luca_\\AppData\\Local\\Temp\\pip-install-oxtzhzjj\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\n",
      "  Complete output (17 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.9\n",
      "  copying src\\pyaudio.py -> build\\lib.win-amd64-3.9\n",
      "  running build_ext\n",
      "  building '_portaudio' extension\n",
      "  creating build\\temp.win-amd64-3.9\n",
      "  creating build\\temp.win-amd64-3.9\\Release\n",
      "  creating build\\temp.win-amd64-3.9\\Release\\src\n",
      "  C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -DMS_WIN64=1 -IC:\\Users\\luca_\\.conda\\envs\\tf\\include -IC:\\Users\\luca_\\.conda\\envs\\tf\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\ATLMFC\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt /Tcsrc/_portaudiomodule.c /Fobuild\\temp.win-amd64-3.9\\Release\\src/_portaudiomodule.obj\n",
      "  _portaudiomodule.c\n",
      "  C:\\Users\\luca_\\.conda\\envs\\tf\\include\\pyconfig.h(117): warning C4005: 'MS_WIN64': ridefinizione macro\n",
      "  src/_portaudiomodule.c: note: vedere la precedente definizione di 'MS_WIN64'\n",
      "  src/_portaudiomodule.c(29): fatal error C1083: Non Š possibile aprire il file inclusione: 'portaudio.h': No such file or directory\n",
      "  error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pyaudio\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'C:\\Users\\luca_\\.conda\\envs\\tf\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\luca_\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oxtzhzjj\\\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\luca_\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oxtzhzjj\\\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\luca_\\AppData\\Local\\Temp\\pip-record-34w_inp9\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\luca_\\.conda\\envs\\tf\\Include\\pyaudio'\n",
      "         cwd: C:\\Users\\luca_\\AppData\\Local\\Temp\\pip-install-oxtzhzjj\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\n",
      "    Complete output (17 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build\\lib.win-amd64-3.9\n",
      "    copying src\\pyaudio.py -> build\\lib.win-amd64-3.9\n",
      "    running build_ext\n",
      "    building '_portaudio' extension\n",
      "    creating build\\temp.win-amd64-3.9\n",
      "    creating build\\temp.win-amd64-3.9\\Release\n",
      "    creating build\\temp.win-amd64-3.9\\Release\\src\n",
      "    C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX86\\x64\\cl.exe /c /nologo /Ox /W3 /GL /DNDEBUG /MD -DMS_WIN64=1 -IC:\\Users\\luca_\\.conda\\envs\\tf\\include -IC:\\Users\\luca_\\.conda\\envs\\tf\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\ATLMFC\\include -IC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\include -IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt -IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt /Tcsrc/_portaudiomodule.c /Fobuild\\temp.win-amd64-3.9\\Release\\src/_portaudiomodule.obj\n",
      "    _portaudiomodule.c\n",
      "    C:\\Users\\luca_\\.conda\\envs\\tf\\include\\pyconfig.h(117): warning C4005: 'MS_WIN64': ridefinizione macro\n",
      "    src/_portaudiomodule.c: note: vedere la precedente definizione di 'MS_WIN64'\n",
      "    src/_portaudiomodule.c(29): fatal error C1083: Non Š possibile aprire il file inclusione: 'portaudio.h': No such file or directory\n",
      "    error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2019\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.29.30133\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'C:\\Users\\luca_\\.conda\\envs\\tf\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\luca_\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oxtzhzjj\\\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\luca_\\\\AppData\\\\Local\\\\Temp\\\\pip-install-oxtzhzjj\\\\pyaudio_493632549b1b4277bb621cee8f7e45ba\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\luca_\\AppData\\Local\\Temp\\pip-record-34w_inp9\\install-record.txt' --single-version-externally-managed --compile --install-headers 'C:\\Users\\luca_\\.conda\\envs\\tf\\Include\\pyaudio' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "V4cVP0NmD71-"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "from json_tricks import load\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "from pydub import AudioSegment, effects\n",
    "import noisereduce as nr\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\luca_\\Desktop\\cpac\\SpeechEmotionRecognition_Realtime\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(cwd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSjs9TReEUls"
   },
   "source": [
    "# **LOAD MODEL**\n",
    "Loading the speech emotion recognition LSTM model and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6qXd1-vD72A",
    "outputId": "9a687758-6391-4ec5-ec83-e52bb0f5ffc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 587, 64)           20480     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 54,024\n",
      "Trainable params: 54,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = 'c:/Users/luca_/Desktop/cpac/Colab Notebooks/model8723.json'\n",
    "saved_weights_path = 'c:/Users/luca_/Desktop/cpac/Colab Notebooks/model8723_weights.h5'\n",
    "\n",
    "#Reading the model from JSON file\n",
    "with open(saved_model_path, 'r') as json_file:\n",
    "    json_savedModel = json_file.read()\n",
    "    \n",
    "# Loading the model architecture, weights\n",
    "model = tf.keras.models.model_from_json(json_savedModel)\n",
    "model.load_weights(saved_weights_path)\n",
    "\n",
    "# Compiling the model with similar parameters as the original model.\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "                optimizer='RMSProp', \n",
    "                metrics=['categorical_accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIrA6eoQGMiH"
   },
   "source": [
    "# **DATA PREPROCESSING**\n",
    "\n",
    "An audio input .wav file is processed similarly to the model's preprocess in the following order:\n",
    "\n",
    "\n",
    "*   Sample rate: number of audio samples per second is extracted by `librosa`.\n",
    "*   'AudioSegment' instance: The audio is loaded to an object by the `AudioSegment` module of `pydub`.\n",
    "*   Normalization: The 'AudioSegment' object is normalized to + 5.0 dBFS, by `effects` module of `pydub`. \n",
    "*   Transforming the object to an array of samples by `numpy` & `AudioSegment`.\n",
    "*   Noise reduction is being performed by `noisereduce`.\n",
    "\n",
    "Speech features are extracted as well:\n",
    "1.   Energy - Root Mean Square (RMS)\n",
    "2.   Zero Crossed Rate (ZCR)\n",
    "3.   Mel-Frequency Cepstral Coefficients (MFCCs) \n",
    "\n",
    "With `frame_length = 2048`, `hop_lentgh = 512`, assuring equally sequential length. \n",
    "\n",
    "The features are concatenated to an '`X`' variable, adjusted to fit the expected shape of the model: (batch, timesteps, feature). The function returns '`X_3D`' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WyCwGZaeD72C"
   },
   "outputs": [],
   "source": [
    "def preprocess(file_path, frame_length = 2048, hop_length = 512):\n",
    "    '''\n",
    "    A process to an audio .wav file before execcuting a prediction.\n",
    "      Arguments:\n",
    "      - file_path - The system path to the audio file.\n",
    "      - frame_length - Length of the frame over which to compute the speech features. default: 2048\n",
    "      - hop_length - Number of samples to advance for each frame. default: 512\n",
    "\n",
    "      Return:\n",
    "        'X_3D' variable, containing a shape of: (batch, timesteps, feature) for a single file (batch = 1).\n",
    "    ''' \n",
    "    # Fetch sample rate.\n",
    "    _, sr = librosa.load(path = file_path, sr = None)\n",
    "    # Load audio file\n",
    "    rawsound = AudioSegment.from_file(file_path, duration = None) \n",
    "    # Normalize to 5 dBFS \n",
    "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
    "    # Transform the audio file to np.array of samples\n",
    "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32') \n",
    "    # Noise reduction                  \n",
    "    final_x = nr.reduce_noise(y = normal_x,sr = sr, y_noise = normal_x)\n",
    "        \n",
    "        \n",
    "    f1 = librosa.feature.rms(final_x, frame_length=frame_length, hop_length=hop_length, center=True, pad_mode='reflect').T # Energy - Root Mean Square\n",
    "    f2 = librosa.feature.zero_crossing_rate(final_x, frame_length=frame_length, hop_length=hop_length,center=True).T # ZCR\n",
    "    f3 = librosa.feature.mfcc(final_x, sr=sr, S=None, n_mfcc=13, hop_length = hop_length).T # MFCC   \n",
    "    X = np.concatenate((f1, f2, f3), axis = 1)\n",
    "    \n",
    "    X_3D = np.expand_dims(X, axis=0)\n",
    "    \n",
    "    return X_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuiRFk30CDGs"
   },
   "source": [
    "# **ADDITIONAL SETUP**\n",
    "- An **emotion list** is defined to translate the model prediction output to a readable form.\n",
    "\n",
    "- `is_silent` function is executed as a boolean state if silence of sequential audio was found. `is_silent` returns `True` when the maximum signal within the sequence is less than the threshold value defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vXfNZp8qD72D"
   },
   "outputs": [],
   "source": [
    "# Emotions list is created for a readable form of the model prediction.\n",
    "\n",
    "emotions = {\n",
    "    0 : 'neutral',\n",
    "    1 : 'calm',\n",
    "    2 : 'happy',\n",
    "    3 : 'sad',\n",
    "    4 : 'angry',\n",
    "    5 : 'fearful',\n",
    "    6 : 'disgust',\n",
    "    7 : 'suprised'   \n",
    "}\n",
    "emo_list = list(emotions.values())\n",
    "\n",
    "def is_silent(data):\n",
    "    # Returns 'True' if below the 'silent' threshold\n",
    "    return max(data) < 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nmp_ojL4Urt"
   },
   "source": [
    "# **REAL-TIME IMPLEMENTATION**\n",
    "\n",
    "This implementation of an LSTM Speech Emotion Recognition model carries out a real-time emotion prediction of an audio input, recorded from the soundcard of the platform.\n",
    "The process includes the following:\n",
    "\n",
    "\n",
    "1.   Session start, opening a connection with the input channel by `pyaudio`.\n",
    "2.   If **not silent**, the input signals will be recorded to a .wav file, by `pyaudio` and `wave`.\n",
    "\n",
    "    2.1  After 7.1 seconds, the recording will stumble in order to send the last .wav file to the rest of the process before start recording a new one.\n",
    "\n",
    "    2.2  The .wav file is preprocessed, in `preprocess` function.\n",
    "\n",
    "    2.3  `model.predict` is executed, an array of 8 emotion probabilities is returned. E.g. `predictions = [array([p_neutral, p_calm, p_happy, p_sad, p_angry, p_feaful, p_disgust, p_suprised], dtype=float32)]`\n",
    "\n",
    "    2.4   `predictions` are transformed to a compact representation (without 'array' and 'dtype' statements) and saved in a list.\n",
    "\n",
    "    2.5 A visualization of `predictions` is shown by `matplotlib`.\n",
    "\n",
    "3.   Else, if silence is identified within the last 2 seconds of a .wav file:\n",
    "\n",
    "    3.1  Break; end of the session; close connections.\n",
    "\n",
    "    3.2 Visualize a summary of the session: Mean value of the predictions.\n",
    "\n",
    "    3.3 State the overall session time.\n",
    "\n",
    "\n",
    "## **VARIABLES EXPLAINED**\n",
    "RATE = Sample rate = 24414 which is the sample rate of most of the model's train data.\n",
    "\n",
    "CHUNK = A batch of sequential samples to process at once. Similar to 'hop_length' by `librosa`, defined 512.\n",
    "\n",
    "FORMAT = Sampling size and format, 32bit as in the model.\n",
    "\n",
    "CHANNELS = 1 for mono, a standard of audio recording in PC / cellphones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4s4DyZckD72E",
    "outputId": "862921df-ad36-4b23-9532-81762f128793"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyaudio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1788/628419301.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyaudio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyaudio'"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "\n",
    "# Initialize variables\n",
    "RATE = 24414\n",
    "CHUNK = 512\n",
    "RECORD_SECONDS = 7.1\n",
    "\n",
    "FORMAT = pyaudio.paInt32\n",
    "CHANNELS = 1\n",
    "WAVE_OUTPUT_FILE = \"/content/drive/My Drive/Colab Notebooks/output.wav\"\n",
    "\n",
    "# Open an input channel\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "\n",
    "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
    "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
    "\n",
    "# SESSION START\n",
    "print(\"** session started\")\n",
    "total_predictions = [] # A list for all predictions in the session.\n",
    "tic = time.perf_counter()\n",
    "\n",
    "while is_silent(data) == False:\n",
    "    print(\"* recording...\")\n",
    "    frames = [] \n",
    "    data = np.nan # Reset 'data' variable.\n",
    "\n",
    "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
    "\n",
    "    # Insert frames to 'output.wav'.\n",
    "    for i in range(0, timesteps):\n",
    "        data = array('l', stream.read(CHUNK)) \n",
    "        frames.append(data)\n",
    "\n",
    "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(\"* done recording\")\n",
    "\n",
    "    x = preprocess(WAVE_OUTPUT_FILE) # 'output.wav' file preprocessing.\n",
    "    # Model's prediction => an 8 emotion probabilities array.\n",
    "    predictions = model.predict(x, use_multiprocessing=True)\n",
    "    pred_list = list(predictions)\n",
    "    pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0) # Get rid of 'array' & 'dtype' statments.\n",
    "    total_predictions.append(pred_np)\n",
    "    \n",
    "    # Present emotion distribution for a sequence (7.1 secs).\n",
    "    fig = plt.figure(figsize = (10, 2))\n",
    "    plt.bar(emo_list, pred_np, color = 'darkturquoise')\n",
    "    plt.ylabel(\"Probabilty (%)\")\n",
    "    plt.show()\n",
    "    \n",
    "    max_emo = np.argmax(predictions)\n",
    "    print('max emotion:', emotions.get(max_emo,-1))\n",
    "    \n",
    "    print(100*'-')\n",
    "    \n",
    "    # Define the last 2 seconds sequence.\n",
    "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
    "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
    "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
    "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
    "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
    "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
    "                                                                            axis =0)) , dtype = 'b')\n",
    "    if is_silent(last_frames): # If the last 2 seconds are silent, end the session.\n",
    "        break\n",
    "\n",
    "# SESSION END        \n",
    "toc = time.perf_counter()\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "wf.close()\n",
    "print('** session ended')\n",
    "\n",
    "# Present emotion distribution for the whole session.\n",
    "total_predictions_np =  np.mean(np.array(total_predictions).tolist(), axis=0)\n",
    "fig = plt.figure(figsize = (10, 5))\n",
    "plt.bar(emo_list, total_predictions_np, color = 'indigo')\n",
    "plt.ylabel(\"Mean probabilty (%)\")\n",
    "plt.title(\"Session Summary\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Emotions analyzed for: {(toc - tic):0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "from array import array\n",
    "import struct\n",
    "import time\n",
    "\n",
    "WAVE_OUTPUT_FILE = 'c:/Users/luca_/Desktop/cpac/Colab Notebooks/output.wav'\n",
    "x = preprocess(WAVE_OUTPUT_FILE)\n",
    "\n",
    "predictions = model.predict(x, use_multiprocessing=True)\n",
    "pred_list = list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1989157e-05 6.7378871e-02 1.2235611e-03 9.8827131e-02 3.4797393e-02\n",
      "  1.2002611e-02 4.7975636e-01 3.0599207e-01]]\n"
     ]
    }
   ],
   "source": [
    "#print(pred_list)\n",
    "\n",
    "#predictions\n",
    "print(np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0)\n",
    "#total_predictions_np =  np.array(pred_list)\n",
    "fig = plt.figure(figsize = (10, 2))\n",
    "plt.bar(emo_list, pred_np,color = 'darkturquoise')\n",
    "plt.ylabel(\"Probabilty (%)\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "3_realtime_ser.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
